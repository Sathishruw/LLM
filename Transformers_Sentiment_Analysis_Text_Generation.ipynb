{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78cd9407",
   "metadata": {},
   "source": [
    "\n",
    "# Sentiment Analysis and Text Generation with Transformers\n",
    "\n",
    "This notebook demonstrates how to use Hugging Face's `transformers` library to perform sentiment analysis with a DistilBERT model and text generation with a GPT-2 model.\n",
    "\n",
    "## About the Models\n",
    "\n",
    "### DistilBERT\n",
    "\n",
    "DistilBERT is a smaller, faster, cheaper, and lighter version of BERT (Bidirectional Encoder Representations from Transformers). It is created by Hugging Face by applying knowledge distillation to the BERT model, reducing its size while retaining 97% of its language understanding capabilities and being 60% faster.\n",
    "\n",
    "BERT was introduced by Google in 2018 and is designed to pre-train deep bidirectional representations by jointly conditioning on both left and right context in all layers. This allows the model to understand the context of a word based on its surroundings, making it highly effective for various NLP tasks such as sentiment analysis, question answering, and more.\n",
    "\n",
    "### GPT-2\n",
    "\n",
    "GPT-2 (Generative Pre-trained Transformer 2) is a large-scale, unsupervised language model created by OpenAI. It is trained to predict the next word in 40GB of Internet text. GPT-2 generates coherent and contextually relevant text based on a given prompt. Released in 2019, it has shown impressive results in tasks such as text generation, translation, and summarization.\n",
    "\n",
    "## Importing the Necessary Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f3efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b690d8",
   "metadata": {},
   "source": [
    "\n",
    "## Initializing the Pipelines\n",
    "\n",
    "We will initialize two pipelines: one for sentiment analysis using the DistilBERT model and one for text generation using the GPT-2 model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df0dae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the sentiment analysis pipeline with DistilBERT model\n",
    "classifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "\n",
    "# Initialize the text generation pipeline with GPT-2 Small model\n",
    "generator = pipeline('text-generation', model='gpt2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fa2a06",
   "metadata": {},
   "source": [
    "\n",
    "## Defining Functions for Sentiment Analysis and Text Generation\n",
    "\n",
    "We define two functions: one to perform sentiment analysis and one to generate text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47148dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to perform sentiment analysis on a given text\n",
    "def sentiment_analysis_demo(text):\n",
    "    \"\"\"\n",
    "    Analyzes the sentiment of the input text using DistilBERT model.\n",
    "    \n",
    "    Parameters:\n",
    "    text (str): The text to analyze sentiment for.\n",
    "    \n",
    "    Prints the sentiment label and the confidence score.\n",
    "    \"\"\"\n",
    "    result = classifier(text)  # Perform sentiment analysis\n",
    "    # Print the result in a formatted way\n",
    "    print(f\"Text: {text}\\nSentiment: {result[0]['label']} (Score: {result[0]['score']:.4f})\")\n",
    "\n",
    "# Define a function to generate text based on a given prompt\n",
    "def text_generation_demo(prompt):\n",
    "    \"\"\"\n",
    "    Generates text based on the input prompt using GPT-2 model.\n",
    "    \n",
    "    Parameters:\n",
    "    prompt (str): The initial text prompt to generate text from.\n",
    "    \n",
    "    Prints the generated text.\n",
    "    \"\"\"\n",
    "    result = generator(prompt, max_length=50, num_return_sequences=1)  # Generate text\n",
    "    # Print the prompt and the generated text in a formatted way\n",
    "    print(f\"Prompt: {prompt}\\nGenerated Text: {result[0]['generated_text']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d119e492",
   "metadata": {},
   "source": [
    "\n",
    "## Example Usage\n",
    "\n",
    "We demonstrate the usage of the sentiment analysis and text generation functions with example inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220032fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage of sentiment analysis function\n",
    "sentiment_analysis_demo(\"OpenAI's technology is revolutionizing the AI landscape.\")\n",
    "\n",
    "# Example usage of text generation function\n",
    "text_generation_demo(\"Once upon a time in a faraway land\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
